{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install crewai crewai-tools poetry vllm\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!pip install pymupdf langchain-community langchain-core langgraph faiss-cpu\n",
        "!pip install langchain --upgrade"
      ],
      "metadata": {
        "id": "oNDO0yFm6ok2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve > ollama.log &\n",
        "!nohup ollama run llava:7b &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uDO5w6tRNYP",
        "outputId": "6e45db49-fe83-44e5-f1e5-b35d2589a8f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: redirecting stderr to stdout\n",
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymupdf  # PyMuPDF\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Caminho do arquivo ZIP enviado pelo usuário\n",
        "zip_path = \"RAG.zip\"\n",
        "extracted_path = \"extracted_pdfs\"\n",
        "\n",
        "# Extraindo os PDFs\n",
        "os.makedirs(extracted_path, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "# Função para extrair texto de PDFs\n",
        "def extract_text_from_pdfs(pdf_folder):\n",
        "    text_data = \"\"\n",
        "    for pdf_file in os.listdir(pdf_folder):\n",
        "        if pdf_file.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "            doc = pymupdf.open(pdf_path)\n",
        "            for page in doc:\n",
        "                text_data += page.get_text(\"text\") + \"\\n\\n\"\n",
        "    return text_data\n",
        "\n",
        "# Extraindo texto dos PDFs\n",
        "medical_texts = extract_text_from_pdfs(extracted_path)\n",
        "\n",
        "# Salvando em um arquivo de texto\n",
        "medical_texts_path = \"medical_texts.txt\"\n",
        "with open(medical_texts_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(medical_texts)\n",
        "\n",
        "# Retornar o caminho do arquivo salvo\n",
        "medical_texts_path\n"
      ],
      "metadata": {
        "id": "0zYWJxJibi_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain supports many other chat models. Here, we're using Ollama\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# supports many more optional parameters. Hover on your `ChatOllama(...)`\n",
        "# class to view the latest available supported parameters\n",
        "llm = ChatOllama(model=\"llava:7b\")\n",
        "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
        "\n",
        "# using LangChain Expressive Language chain syntax\n",
        "# learn more about the LCEL on\n",
        "# /docs/expression_language/why\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# for brevity, response is printed in terminal\n",
        "# You can use LangServe to deploy your application for\n",
        "# production\n",
        "print(chain.invoke({\"topic\": \"Space travel\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiR44_K19-2S",
        "outputId": "3d0a5b42-4a0e-4c94-e862-af306fd8018f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8b2e26c1fe6e>:8: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
            "  llm = ChatOllama(model=\"llava:7b\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Why did the astronaut go to space?\n",
            "\n",
            "To explore strange new worlds, to seek out new life and new civilizations, to boldly go where no one has gone before. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHYDPFDXa9qc",
        "outputId": "b86ea7a7-8753-4e6d-ff92-0ec041346126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Pregel.stream at 0x7db587b9a8f0>\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "from langchain_community.vectorstores.faiss import FAISS\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain.pydantic_v1 import BaseModel\n",
        "\n",
        "\n",
        "# Carregar embeddings do Sentence-Transformers\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Carregar e processar documentos médicos (já extraídos dos PDFs)\n",
        "loader = TextLoader(\"medical_texts.txt\")  # Arquivo consolidado com informações médicas extraídas\n",
        "texts = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "documents = text_splitter.split_documents(texts)\n",
        "\n",
        "# Criar banco vetorial FAISS\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Configurar modelo LLM\n",
        "llm = ChatOllama(model=\"llava:7b\")  # Trocar conforme necessário\n",
        "\n",
        "# Configurar agentes\n",
        "class DiagnosticAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    def analyze_lesion(self, state):\n",
        "        # Simulação da análise de imagem segmentada\n",
        "        return {\"diagnosis\": self.llm.invoke(state.image_data).content}#\"Lesão apresenta pigmentação irregular e bordas assimétricas. Possível risco moderado.\"}\n",
        "\n",
        "class PrognosticAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    def assess_risk(self, state):\n",
        "      return {\"prognosis\": \"Baseado no diagnóstico, a lesão tem 60% de chance de ser maligna.\"}\n",
        "\n",
        "class SummaryAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    def summarize(self, state):\n",
        "        return {\n",
        "            \"diagnosis\": state.diagnosis,\n",
        "            \"prognosis\": state.prognosis,\n",
        "            \"validation\": \"Recomenda-se biópsia para confirmação.\"\n",
        "        }\n",
        "\n",
        "# Configurar agente crítico\n",
        "class CriticalReviewAgent:\n",
        "    def __init__(self, retriever, llm):\n",
        "        self.retriever = retriever\n",
        "        self.llm = llm\n",
        "\n",
        "    def validate_diagnosis(self, state):\n",
        "        retrieved_docs = self.retriever.invoke(state.diagnosis)\n",
        "        return {\"final_report\": f\"Confirmação baseada em literatura médica: {retrieved_docs[0].page_content[:200]}...\"}\n",
        "\n",
        "\n",
        "# Definir o esquema de estado inicial\n",
        "class GraphState(BaseModel):\n",
        "    image_data: str\n",
        "    diagnosis: str = None\n",
        "    prognosis: str = None\n",
        "    validation: str = None\n",
        "    final_report: str = None\n",
        "\n",
        "\n",
        "# Criar fluxo no LangGraph\n",
        "graph = StateGraph(GraphState)\n",
        "\n",
        "graph.add_node(\"diagnostic\", DiagnosticAgent(llm).analyze_lesion)\n",
        "graph.add_node(\"prognostic\", PrognosticAgent(llm).assess_risk)\n",
        "graph.add_node(\"summary\", SummaryAgent(llm).summarize)\n",
        "graph.add_node(\"critical_review\", CriticalReviewAgent(retriever, llm).validate_diagnosis)\n",
        "\n",
        "# Definir conexões do fluxo\n",
        "graph.add_edge(START, \"diagnostic\")\n",
        "graph.add_edge(\"diagnostic\", \"prognostic\")\n",
        "graph.add_edge(\"prognostic\", \"summary\")\n",
        "graph.add_edge(\"summary\", \"critical_review\")\n",
        "graph.add_edge(\"critical_review\", END)\n",
        "\n",
        "g = graph.compile()\n",
        "\n",
        "# Executar o fluxo de teste\n",
        "output = g.stream({\"image_data\": \"imagem_segmentada_mock\"}, stream_mode=\"values\")\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = llm.invoke(\"imagem_segmentada_mock\")"
      ],
      "metadata": {
        "id": "wwVpW8D45Lxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s0TItYu5SIm",
        "outputId": "83201cae-755c-4f14-e810-1fccbf7c37a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=' Imagem segmentada é a tarefa de separar um objeto ou parte de uma imagem do fundo da imagem. Esta tarefa é comum em aplicações como detecção de objetos, reconhecimento facial e análise de imagens médicas.\\n\\nPara executar essa tarefa, geralmente usam-se algoritmos de segmentação de imagens. Alguns desses algoritmos incluem o metodo da máscara, o método do contorno e o método da região de interesse (ROI).\\n\\nO metodo da máscara consiste em dividir a imagem em blocos ou matrizes pequenas e analisar cada uma das peças, enquanto o metodo do contorno analisa as bordas da imagem. O método da ROI envolve identificar a parte da imagem que deve ser segmentada e realizar a segmentação apenas nessa parte.\\n\\nExistam várias bibliotecas e ferramentas disponíveis para facilitar o processo de segmentação de imagens, como OpenCV, Python, C++ e Java. ', additional_kwargs={}, response_metadata={'model': 'llava:7b', 'created_at': '2025-02-26T10:54:47.403378527Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 6184372159, 'load_duration': 18318861, 'prompt_eval_count': 15, 'prompt_eval_duration': 7000000, 'eval_count': 270, 'eval_duration': 6158000000}, id='run-ba53dfd8-b914-4f68-87ed-c58f2d607df4-0')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = g.stream({\"image_data\": \"imagem_segmentada_mock\"}, stream_mode=\"values\")\n",
        "# print(output)\n",
        "\n",
        "for event in g.stream({\"image_data\": \"imagem_segmentada_mock\"}, stream_mode=\"values\"):\n",
        "  print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZC5-B7acvpq",
        "outputId": "d01e7a01-c906-4fba-c3be-edaabd557d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'image_data': 'imagem_segmentada_mock'}\n",
            "{'image_data': 'imagem_segmentada_mock', 'diagnosis': ' Desculpe, não consigo fornecer uma imagem específica sem mais informações. No entanto, posso descrever a funcionalidade geral da segmentação de imagens para você.\\n\\nA segmentação de imagens é um processo que envolve dividir uma imagem em partes menores e definir para cada parte uma classificação ou atributo. Por exemplo, podemos usar segmentação para identificar objetos dentro de uma imagem, destacar a região de interesse ou separar estruturas ou elementos da imagem.\\n\\nHá vários métodos e algoritmos para realizar essa tarefa, como:\\n\\n1. Segmentação por thresholding: onde se define um valor de limiar (threshold) e toda a região acima desse valor é considerada como uma parte do objeto e abaixo é ignorado.\\n2. Segmentação por edge detection: onde são identificados os bordos das partes da imagem e as regiões interiores são definidas.\\n3. Segmentação por clustering: onde se utiliza algoritmos de agrupamento para formar grupos em diferentes partes da imagem.\\n4. Segmentação por learning: onde se utiliza treinamento automático para identificar as regiões importantes na imagem.\\n5. Segmentação por deep learning: onde se utiliza redes neurais para detectar os objetos e dividir a imagem em partes.\\n\\nCada método tem suas vantagens e desvantagens, dependendo do tipo de imagem e dos objetivos da segmentação. '}\n",
            "{'image_data': 'imagem_segmentada_mock', 'diagnosis': ' Desculpe, não consigo fornecer uma imagem específica sem mais informações. No entanto, posso descrever a funcionalidade geral da segmentação de imagens para você.\\n\\nA segmentação de imagens é um processo que envolve dividir uma imagem em partes menores e definir para cada parte uma classificação ou atributo. Por exemplo, podemos usar segmentação para identificar objetos dentro de uma imagem, destacar a região de interesse ou separar estruturas ou elementos da imagem.\\n\\nHá vários métodos e algoritmos para realizar essa tarefa, como:\\n\\n1. Segmentação por thresholding: onde se define um valor de limiar (threshold) e toda a região acima desse valor é considerada como uma parte do objeto e abaixo é ignorado.\\n2. Segmentação por edge detection: onde são identificados os bordos das partes da imagem e as regiões interiores são definidas.\\n3. Segmentação por clustering: onde se utiliza algoritmos de agrupamento para formar grupos em diferentes partes da imagem.\\n4. Segmentação por learning: onde se utiliza treinamento automático para identificar as regiões importantes na imagem.\\n5. Segmentação por deep learning: onde se utiliza redes neurais para detectar os objetos e dividir a imagem em partes.\\n\\nCada método tem suas vantagens e desvantagens, dependendo do tipo de imagem e dos objetivos da segmentação. ', 'prognosis': 'Baseado no diagnóstico, a lesão tem 60% de chance de ser maligna.'}\n",
            "{'image_data': 'imagem_segmentada_mock', 'diagnosis': ' Desculpe, não consigo fornecer uma imagem específica sem mais informações. No entanto, posso descrever a funcionalidade geral da segmentação de imagens para você.\\n\\nA segmentação de imagens é um processo que envolve dividir uma imagem em partes menores e definir para cada parte uma classificação ou atributo. Por exemplo, podemos usar segmentação para identificar objetos dentro de uma imagem, destacar a região de interesse ou separar estruturas ou elementos da imagem.\\n\\nHá vários métodos e algoritmos para realizar essa tarefa, como:\\n\\n1. Segmentação por thresholding: onde se define um valor de limiar (threshold) e toda a região acima desse valor é considerada como uma parte do objeto e abaixo é ignorado.\\n2. Segmentação por edge detection: onde são identificados os bordos das partes da imagem e as regiões interiores são definidas.\\n3. Segmentação por clustering: onde se utiliza algoritmos de agrupamento para formar grupos em diferentes partes da imagem.\\n4. Segmentação por learning: onde se utiliza treinamento automático para identificar as regiões importantes na imagem.\\n5. Segmentação por deep learning: onde se utiliza redes neurais para detectar os objetos e dividir a imagem em partes.\\n\\nCada método tem suas vantagens e desvantagens, dependendo do tipo de imagem e dos objetivos da segmentação. ', 'prognosis': 'Baseado no diagnóstico, a lesão tem 60% de chance de ser maligna.', 'validation': 'Recomenda-se biópsia para confirmação.'}\n",
            "{'image_data': 'imagem_segmentada_mock', 'diagnosis': ' Desculpe, não consigo fornecer uma imagem específica sem mais informações. No entanto, posso descrever a funcionalidade geral da segmentação de imagens para você.\\n\\nA segmentação de imagens é um processo que envolve dividir uma imagem em partes menores e definir para cada parte uma classificação ou atributo. Por exemplo, podemos usar segmentação para identificar objetos dentro de uma imagem, destacar a região de interesse ou separar estruturas ou elementos da imagem.\\n\\nHá vários métodos e algoritmos para realizar essa tarefa, como:\\n\\n1. Segmentação por thresholding: onde se define um valor de limiar (threshold) e toda a região acima desse valor é considerada como uma parte do objeto e abaixo é ignorado.\\n2. Segmentação por edge detection: onde são identificados os bordos das partes da imagem e as regiões interiores são definidas.\\n3. Segmentação por clustering: onde se utiliza algoritmos de agrupamento para formar grupos em diferentes partes da imagem.\\n4. Segmentação por learning: onde se utiliza treinamento automático para identificar as regiões importantes na imagem.\\n5. Segmentação por deep learning: onde se utiliza redes neurais para detectar os objetos e dividir a imagem em partes.\\n\\nCada método tem suas vantagens e desvantagens, dependendo do tipo de imagem e dos objetivos da segmentação. ', 'prognosis': 'Baseado no diagnóstico, a lesão tem 60% de chance de ser maligna.', 'validation': 'Recomenda-se biópsia para confirmação.', 'final_report': 'Confirmação baseada em literatura médica: This work has been submitted to the IEEE for possible publication. Copyright\\nmay be transferred without notice, after which this version may no longer be\\naccessible.\\nImage segmentation tasks can be cl...'}\n"
          ]
        }
      ]
    }
  ]
}